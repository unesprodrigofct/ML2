{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4eb3b92",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lendo as bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "from scipy.stats import ks_2samp\n",
    "from xgboost import plot_importance\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, \\\n",
    "roc_curve, precision_recall_curve, auc, average_precision_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import shap\n",
    "\n",
    "# import scikitplot as skplt\n",
    "\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from bayes_opt import BayesianOptimization\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0153b",
   "metadata": {},
   "source": [
    "# Importanto a base de dados \n",
    "\n",
    "### função read_file\n",
    "A função abaixo vai tentar ler os dados localmente da pasta data, mas caso o arquivo não exista,\n",
    "será baixado o arquivo do s3 e salvo localmente na pasta data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = pd.read_parquet('../data/default_mod_nodoc_ocp3.parquet')\n",
    "\n",
    "df_final = \n",
    "\n",
    "df_final = df_final[df_final['safra'] >= '2019-05']\n",
    "df_final = df_final[df_final['safra'] <= '2022-07']\n",
    "\n",
    "## var resposta\n",
    "target_ = ''\n",
    "df_final = df_final[df_final[target_].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bdc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31db109",
   "metadata": {},
   "source": [
    "## Removendo as Variaveis com nenhuma ou baixa relevancia pro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = []\n",
    "\n",
    "\n",
    "df_final.drop(columns=drop_col,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = df_final.columns.values[15:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dccd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_features))\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00408a72",
   "metadata": {},
   "source": [
    "# Variável Resposta\n",
    "\n",
    "Nessa etapa, vamos visualizar a variável resposta em função do tempo. Alem disso, vamos analisar tammbém a influência do control_group x bad rate no tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stability_target(df,bland):\n",
    "    \n",
    "    plt.figure(figsize=(16, 8)) \n",
    "    figsize=(16,8)\n",
    "    \n",
    "    sns.set(font_scale=1.5) \n",
    "    df[\"safra\"] = pd.to_datetime(df[\"safra\"])\n",
    "    \n",
    "    ax2 = df.groupby(\"safra\")[target_].mean().plot(figsize=figsize,title =bland+ '-target_fpd30')\n",
    "    \n",
    "    \n",
    "    ax2.set(ylim=(0,0.3)) \n",
    "    \n",
    "    plt.savefig(img_path + 'bad rate' +'open')\n",
    "\n",
    "plot_stability_target(df_final,'Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_final = df_final[df_final[target_].notnull()]\n",
    "df_var_final[target_] = df_var_final[target_].astype(int)\n",
    "df_train, df_test = train_test_split(df_var_final,test_size=0.3, random_state=101)\n",
    "print(\"numero de variáveis\",len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2234ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5302d",
   "metadata": {},
   "source": [
    "# Modelo: XGBoost\n",
    "\n",
    "Nesse etapa, vamos criar nosso modelo usando o XGBoost. Para estimar os hyperparâmetro do modelo, vamos usar um Grid Search que vai realizar uma combinação de um range de valores previamente informado e encontrar o melhor modelo, a partir desses valores ja conhecidos. \n",
    "\n",
    "O treinamento do Modelo será feito usando Cross-Validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ec707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdddda1-ece0-45da-a74b-5a79267eabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcded33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[train_features].copy()\n",
    "Y_train = df_train[target_].astype(int).copy()\n",
    "\n",
    "X_test = df_test[train_features].copy()\n",
    "Y_test = df_test[target_].astype(int).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab9c0e",
   "metadata": {},
   "source": [
    "pbounds = {'learning_rate': (0.01, 1.0),\n",
    "    'n_estimators': (10,100),\n",
    "    'max_depth': (3,30),    # Change for \n",
    "    'subsample': (0.1, 1.0),  # Change for Big datasets\n",
    "    'colsample': (0, 1.0),  # Change for Datasets with lots of features\n",
    "    'gamma': (0, 10),\n",
    "    'min_child_weight': (10,100)}\n",
    "\n",
    "\n",
    "def xgboost_hyper_param(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        colsample,\n",
    "                        gamma,\n",
    "                        min_child_weight):   \n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma,\n",
    "        min_child_weight=min_child_weight,\n",
    "        eval_metric = 'auc')\n",
    "    return np.mean(cross_val_score(clf, X_train, Y_train, cv=10, scoring='roc_auc'))\n",
    "    \n",
    "optimizer = BayesianOptimization(\n",
    "        f=xgboost_hyper_param,\n",
    "        pbounds=pbounds,\n",
    "        random_state=1,)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221c573",
   "metadata": {},
   "source": [
    "optimizer.maximize(n_iter=15, init_points=8, acq='ei')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf7b68",
   "metadata": {},
   "source": [
    "parameters = optimizer.max['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413f37c",
   "metadata": {},
   "source": [
    "with open('./config/parameters.json','w') as p:\n",
    "    json.dump(parameters,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config/parameters_optimizer/FL - parameters_fpd30.json','r') as p:\n",
    "    parameters1 = json.load(p)\n",
    "parameters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186189fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"parameters1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(gamma = parameters1['gamma'],\n",
    "                              learning_rate = parameters1['learning_rate'],\n",
    "                              max_depth = int(parameters1['max_depth']),\n",
    "                              min_child_weight =120, #int(parameters1['min_child_weight']),\n",
    "                              n_estimators = int(parameters1['n_estimators']),\n",
    "                              subsample = parameters1['subsample'],\n",
    "                              eval_metric='auc') \n",
    "\n",
    "X_train = df_train[train_features].astype(float)\n",
    "Y_train = df_train[target_].astype(int).copy()\n",
    "xgb_model.fit(X_train,   ## Somente a coluna das variáveis explicativas\n",
    "        Y_train)   ## Variável resposta\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cee7f2",
   "metadata": {},
   "source": [
    "# Validação do Modelo \n",
    "\n",
    "A Validação do modelo será feita, calculando:\n",
    "\n",
    "\n",
    "* ROC e KS na base de teste\n",
    "* ROC por Safra\n",
    "* Gráfico de Feature importance (métrica: SHAP)\n",
    "* SHAP das variaves \n",
    "* Gráfico de dependências Parciais\n",
    "* Gráficos para analise da distribuição da probabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ks(df,target):  \n",
    "    \n",
    "    df_default_0 = df.loc[df[target] == 0]\n",
    "    df_default_1 = df.loc[df[target] == 1]\n",
    "    \n",
    "    return ks_2samp(df_default_0[\"Probability\"],df_default_1[\"Probability\"])\n",
    "\n",
    "def get_ks_safra(df,target_,prob_):\n",
    "    \n",
    "    \n",
    "    df['safra'] = pd.to_datetime(df['safra']).dt.strftime('%Y-%m')\n",
    "    ks = []\n",
    "    dt = []\n",
    "    figsize=(10,5)\n",
    "    safra = df.sort_values(\"safra\").safra.unique()\n",
    "    for s in safra:   \n",
    "        df_temp = df[df[\"safra\"] == s]\n",
    "        \n",
    "        \n",
    "        ks_ = get_ks(df =  df_temp,target = target_,prob = prob_)\n",
    "        ks.append(ks_)\n",
    "        dt.append(s)   \n",
    "                          \n",
    "    df_ks = pd.DataFrame({'safra':dt,\n",
    "                          'KS':ks})           \n",
    "    return df_ks\n",
    "\n",
    "\n",
    "def evaluate_model(df_train,df_test,target,model,train_features):\n",
    "    \n",
    "    df_train['Probability'] = model.predict_proba(df_train[train_features])[:,1]\n",
    "    df_test['Probability'] = model.predict_proba(df_test[train_features])[:,1]\n",
    "         \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (14, 6))\n",
    "    # Plot AUC Curve\n",
    "\n",
    "    fpr_train, tpr_train, threshold_train = roc_curve(df_train[target], df_train['Probability'])\n",
    "    roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "    fpr_test, tpr_test, threshold_test = roc_curve(df_test[target], df_test['Probability'])\n",
    "    roc_auc_test = auc(fpr_test, tpr_test)\n",
    "    sns.set(font_scale=1.5) \n",
    "    title = 'Receiver Operating Characteristic (ROC) Curve' \n",
    "    ax = axes[0]\n",
    "    ax.plot(fpr_train , tpr_train , color='darkorange', label = 'AUC = {}'.format(round(roc_auc_train,3))) \n",
    "    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.set_title('Train - ' +target_)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.plot(fpr_test , tpr_test , color='darkorange', label = 'AUC = {}'.format(round(roc_auc_test,3))) \n",
    "    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.set_title('Validation - ' +target_)\n",
    "    \n",
    "     \n",
    "    fig.suptitle(title)\n",
    "    plt.savefig(img_path + 'auc roc' +'open_' + target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99010168",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df_train = df_train\n",
    "               ,df_test = df_test\n",
    "               ,target  =  target_\n",
    "               ,model   = xgb_model\n",
    "               ,train_features =  train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train')\n",
    "print(get_ks(df_train,target_))\n",
    "print('Test')\n",
    "print(get_ks(df_test,target_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_safra(df_test,df_train,target):\n",
    "    \n",
    "    df_safra = df_test.append(df_train)\n",
    "    df_safra['safra'] = pd.to_datetime(df_safra['safra']).dt.strftime('%Y-%m')\n",
    "    roc = []\n",
    "    figsize=(10,5)\n",
    "    safra = df_safra.sort_values(\"safra\").safra.unique()\n",
    "    for s in safra:   \n",
    "        df_temp = df_safra[df_safra[\"safra\"] == s]\n",
    "        fpr, tpr, threshold = roc_curve(df_temp[target], df_temp['Probability'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc.append(roc_auc)\n",
    "    sns.set(font_scale=1.5) \n",
    "    df_safra_roc = pd.DataFrame({\"safra\":safra,\"auc_roc\":roc})\n",
    "    df_safra_roc['safra'] = pd.to_datetime(df_safra_roc['safra'])\n",
    "    df_safra_roc = df_safra_roc.set_index('safra')\n",
    "    ax = df_safra_roc.plot(figsize = figsize)\n",
    "    ax.set(ylim=(0.4, 1))\n",
    "    ax.set_title('AUC ROC ' + 'fpd30')\n",
    "    plt.savefig(img_path + 'roc_safra' +'open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_auc_safra(df_test,df_train,target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ks_safra(df_test,df_train,target):\n",
    "    \n",
    "    df_safra = df_test.append(df_train)\n",
    "    df_safra['safra'] = pd.to_datetime(df_safra['safra']).dt.strftime('%Y-%m')\n",
    "    ks = []\n",
    "    dt = []\n",
    "    figsize=(10,5)\n",
    "    safra = df_safra.sort_values(\"safra\").safra.unique()\n",
    "    for s in safra:   \n",
    "        df_temp = df_safra[df_safra[\"safra\"] == s]\n",
    "        ks_ = get_ks(df =  df_temp,target = target_)\n",
    "        ks.append(ks_[0])\n",
    "        dt.append(s)   \n",
    "       \n",
    "    df_ks = pd.DataFrame({'safra':dt,\n",
    "                          'KS':ks}).set_index('safra')\n",
    "                          \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (14, 6))\n",
    "    ax = df_ks.plot(ax = ax,title = 'KS por Safra')\n",
    "    ax.set(ylim=(0.25,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ks_safra(df_test = df_test, df_train = df_train, target= target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ca21f",
   "metadata": {},
   "source": [
    "### Distribuição da prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab0081-4cc1-41a7-b0b7-4cf6e596720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=False)\n",
    "sns.set(font_scale=1) \n",
    "ay = sns.kdeplot(ax=axes[0],data=df_temp, x=\"Probability\", common_norm=False,hue='sacam_tudo',fill=True,color= [\"blue\",\"red\"])\n",
    "ax = sns.boxplot(ax=axes[1],x='sacam_tudo', y=\"Probability\", data=df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17b6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6302ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Features Importance das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "xgb_model_shap = xgb_model\n",
    "shap_values = shap.TreeExplainer(xgb_model_shap).shap_values(df_train[train_features])\n",
    "shap.summary_plot(shap_values, df_train[train_features].reset_index().drop(columns=\"index\"),show=False)\n",
    "plt.title('Impact Positive or Negative on Probability Model')\n",
    "plt.savefig(img_path + 'shap_impact_' +target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676ea74-3d2f-4302-8fc1-b8f33c01ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Open_Finance_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(xgb_model_shap).shap_values(df_test[train_features])\n",
    "shap.summary_plot(shap_values, df_test[train_features], plot_type=\"bar\",title=\"Feature Importance\",show = False)\n",
    "plt.title('Feature Importance - ' + str(target_))\n",
    "plt.savefig(img_path + 'shap_feature_importance_' +target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([train_features, shap_sum.tolist()]).T\n",
    "importance_df.columns = ['column_name', 'shap_importance']\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9484d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = importance_df.sort_values(\"shap_importance\",ascending = False)[\"column_name\"][0:6].values\n",
    "features2 = importance_df.sort_values(\"shap_importance\",ascending = False)[\"column_name\"][7:13].values\n",
    "features3 = importance_df.sort_values(\"shap_importance\",ascending = False)[\"column_name\"][14:21].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3029fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df[importance_df.shap_importance <= 0.0][\"column_name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50faafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(importance_df['column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vars = importance_df.sort_values(\"shap_importance\",ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787e5ea",
   "metadata": {},
   "source": [
    "### Dependências  Parciais das Variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38486e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep = df_test[df_test[\"scrcrdpnm6mmlv3\"].notnull()]\n",
    "df_dep = df_dep[df_dep[\"trend_ploan_due_3m\"].notnull()]\n",
    "sns.set(font_scale=1.5) \n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plot_partial_dependence(xgb_model,\n",
    "                        features=features1, \n",
    "                        X=df_dep[train_features], \n",
    "                        feature_names=train_features)\n",
    "plt.savefig(img_path + 'partial_dependence1' +target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plot_partial_dependence(xgb_model,\n",
    "                        features=features2, \n",
    "                        X=df_dep[train_features], \n",
    "                        feature_names=train_features)\n",
    "plt.savefig(img_path + 'partial_dependence2' +target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,12)})\n",
    "plot_partial_dependence(xgb_model,\n",
    "                        features=features3, \n",
    "                        X=df_dep[train_features], \n",
    "                        feature_names=train_features)\n",
    "plt.savefig(img_path + 'partial_dependence3' +target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642b869",
   "metadata": {},
   "source": [
    "# Análise por Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dcb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_brand(df_train,df_test,target,model,train_features,brand,color):\n",
    "    \n",
    "    df_train['Probability'] = model.predict_proba(df_train[train_features])[:,1]\n",
    "    df_test['Probability'] = model.predict_proba(df_test[train_features])[:,1]\n",
    "         \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (12, 5))\n",
    "    # Plot AUC Curve\n",
    "\n",
    "    fpr_train, tpr_train, threshold_train = roc_curve(df_train[target], df_train['Probability'])\n",
    "    roc_auc_train = auc(fpr_train, tpr_train)\n",
    "    \n",
    "    fpr_test, tpr_test, threshold_test = roc_curve(df_test[target], df_test['Probability'])\n",
    "    roc_auc_test = auc(fpr_test, tpr_test)\n",
    "    sns.set(font_scale=1) \n",
    "    title = brand + '- ROC' \n",
    "    ax = axes[0]\n",
    "    ax.plot(fpr_train , tpr_train , color=color, label = 'AUC = {}'.format(round(roc_auc_train,3))) \n",
    "    ax.plot([0, 1], [0, 1], color=color, linestyle='--')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.set_title('Train')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.plot(fpr_test , tpr_test , color=color, label = 'AUC = {}'.format(round(roc_auc_test,3))) \n",
    "    ax.plot([0, 1], [0, 1], color=color, linestyle='--')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.set_title('Validation')\n",
    "    \n",
    "     \n",
    "    fig.suptitle(title)\n",
    "    plt.savefig(img_path + 'auc roc' + brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_brand(df_train = df_train[df_train['brand'] == 'GERU']\n",
    "               ,df_test = df_test[df_test['brand'] == 'GERU']\n",
    "               ,target  =  target_\n",
    "               ,model   = xgb_model\n",
    "               ,train_features =  train_features\n",
    "               ,brand = 'GERU'\n",
    "               ,color = 'darkblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c419d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_brand(df_train = df_train[df_train['brand'] == 'REBEL']\n",
    "               ,df_test = df_test[df_test['brand'] == 'REBEL']\n",
    "               ,target  =  target_\n",
    "               ,model   = xgb_model\n",
    "               ,train_features =  train_features\n",
    "               ,brand = 'REBEL'\n",
    "               ,color = 'darkgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebaf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_safra_brand(df_test,df_train,target):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (12, 7))\n",
    "    \n",
    "    df_safra = df_test.append(df_train)\n",
    "    \n",
    "    \n",
    "    df_safra['safra'] = pd.to_datetime(df_safra['safra']).dt.strftime('%Y-%m')\n",
    "    roc_geru = []\n",
    "    roc_rebel = []\n",
    "    figsize=(15,8)\n",
    "    safra = df_safra.sort_values(\"safra\").safra.unique()\n",
    "    \n",
    "    \n",
    "    df_geru = df_safra[df_safra['brand'] == 'GERU']\n",
    "    df_rebel = df_safra[df_safra['brand'] == 'REBEL']\n",
    "    \n",
    "    for s in df_geru.safra.unique():   \n",
    "        df_temp_g = df_geru[df_geru[\"safra\"] == s]\n",
    "        fpr_g, tpr_g, threshold_g = roc_curve(df_temp_g[target], df_temp_g['Probability'])\n",
    "        roc_auc_geru = auc(fpr_g, tpr_g)\n",
    "        roc_geru.append(roc_auc_geru)\n",
    "        \n",
    "        \n",
    "    df_safra_roc_geru = pd.DataFrame({\"safra\":df_geru.safra.unique(),\"auc_roc\":roc_geru})\n",
    "    df_safra_roc_geru['safra'] = pd.to_datetime(df_safra_roc_geru['safra'])\n",
    "    df_safra_roc_geru = df_safra_roc_geru.set_index('safra')\n",
    "        \n",
    "    for s in df_rebel.safra.unique():   \n",
    "        df_temp_r = df_rebel[df_rebel[\"safra\"] == s]\n",
    "        fpr_r, tpr_r, threshold_r = roc_curve(df_temp_r[target], df_temp_r['Probability'])\n",
    "        roc_auc_rebel = auc(fpr_r, tpr_r)\n",
    "        roc_rebel.append(roc_auc_rebel)   \n",
    "    \n",
    "    \n",
    "    df_safra_roc_rebel= pd.DataFrame({\"safra\":df_rebel.safra.unique(),\"auc_roc\":roc_rebel})\n",
    "    df_safra_roc_rebel['safra'] = pd.to_datetime(df_safra_roc_rebel['safra'])\n",
    "    df_safra_roc_rebel = df_safra_roc_rebel.set_index('safra') \n",
    "\n",
    "    \n",
    "    \n",
    "    sns.set(font_scale=1.5)\n",
    "    ax1 = axes[0]\n",
    "    ax1 = df_safra_roc_geru.plot(ax = ax1,figsize = figsize)\n",
    "    ax1.set(ylim=(0.4, 1))\n",
    "    ax1.set_title('Geru - AUC ROC')\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    ax2 = df_safra_roc_rebel.plot(ax = ax2,figsize = figsize)\n",
    "    ax2.set(ylim=(0.4, 1))\n",
    "    ax2.set_title('Rebel - AUC ROC')\n",
    "     \n",
    "    \n",
    "    \n",
    "    plt.savefig(img_path + 'roc_safra_brand' +'open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6be987",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_auc_safra_brand(df_test,df_train,target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_dist_(df,brand):\n",
    "    sns.reset_orig()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=False)\n",
    "    sns.set(font_scale=1) \n",
    "    ay = sns.kdeplot(ax=axes[0],data=df, x=\"Probability\", common_norm=False,hue=target_,fill=True,color= [\"blue\",\"red\"])\n",
    "    ax = sns.boxplot(ax=axes[1],x=target_, y=\"Probability\", data=df_test)\n",
    "    fig.suptitle(brand)\n",
    "    plt.savefig(img_path + 'dist_brand'+brand +target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc75b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_(df_test[df_test['brand'] == 'GERU'],'geru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd138a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_(df_test[df_test['brand'] == 'REBEL'],'rebel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da0310",
   "metadata": {},
   "source": [
    "# Criando Rating\n",
    "\n",
    "No final do processo, vamos criar um rating para categorizar a probabilidade do modelo de tal forma que seja ordenavel. Dessa forma, vamos usar um método de clusterização da probabilidade que vai dividir a base em grupos. \n",
    "\n",
    "Após esse Processo, vamos criar um gráfico que mostra a estabilidade dos ratings em função do tempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414938a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from feature_engine.discretisation import EqualWidthDiscretiser\n",
    "from feature_engine.discretisation import DecisionTreeDiscretiser\n",
    "from utils.ratings_funcoes_de_viz.ratings_funcoes_de_viz import statistic_anl_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins(df,bin_,,stat):\n",
    "    \n",
    "    probs = df[[prob]]\n",
    "    \n",
    "    discretizer21 = KBinsDiscretizer(n_bins=bin_, encode='ordinal', strategy='kmeans')\n",
    "    discretizer21.fit(probs)\n",
    "    discretizer21_transf = discretizer21.transform(probs)\n",
    "    \n",
    "    probs01 = pd.DataFrame(probs)\n",
    "    probs01 = probs01.reset_index()\n",
    "    discretizer21_transf = pd.DataFrame(discretizer21_transf)\n",
    "    discretizer21_transf = pd.concat([probs01, discretizer21_transf], axis=1)\n",
    "\n",
    "    df_corte = discretizer21_transf.groupby(0, as_index = False).agg({'Open_Finance_Score':['size','min', 'mean', 'median', 'max']})\n",
    "    return df_corte[\"Open_Finance_Score\"][stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4db983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_test = df_test[df_test['safra'] <= '2021-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_train = df_train[df_train['safra'] <= '2021-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_rating_test.append(df_rating_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ = get_bins(df_full,4,stat = \"median\")\n",
    "print(bin_)\n",
    "bins_   = [0,0.65,1]\n",
    "print(bins_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c0a09-f9b7-4e41-ad4d-cf02ffac8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_[3] = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = [0,bin_[3]]\n",
    "upper_limit = [bin_[3],1]\n",
    "rating = {'rating':['1','2'],\n",
    "          'lower_limit':lower_limit,\n",
    "          'upper_limit':upper_limit}\n",
    "\n",
    "rating = pd.DataFrame(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7593a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(font_scale=1.2) \n",
    "# hide axes\n",
    "fig.patch.set_visible(True)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(10, 4), columns=list('ABCD'))\n",
    "\n",
    "ax.table(cellText=rating.values, colLabels=rating.columns, loc='center')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(img_path + 'rating_table_' +target_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_train = df_train[df_train['safra'] >= '2021-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_test = df_test[df_test['safra'] >= '2021-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47a608",
   "metadata": {},
   "source": [
    "## Aplicando o Rating na base Inteira (treino + test)\n",
    "## mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,7)})\n",
    "sns.set(font_scale=2) \n",
    "df_full = df_rating_test.append(df_rating_train)\n",
    "df_full['rating'] = pd.cut(df_full[\"score\"] , bins=bins_,labels=['Approved','Declined'])\n",
    "statistic_anl_categ(df_full, target_, 'rating','')\n",
    "plt.savefig(img_path + 'rating_all_df' +target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab0ce9-1758-412d-993d-7b02a585d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full['safra'] == '2022-06-01']['fpd30'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda3)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "vscode": {
   "interpreter": {
    "hash": "0eeaeb142a75347dfcbd4b902d92ec99b5bed5abf0f371f4a9d9f870d18cf86e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
